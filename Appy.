# app.py
from flask import Flask, request, render_template_string
import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
import io
import torchvision.transforms as T

# â€”â€”â€”â€”â€”â€”â€” Model Definition â€”â€”â€”â€”â€”â€”â€”

class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1, bias=False)
        self.bn1   = nn.BatchNorm2d(channels)
        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1, bias=False)
        self.bn2   = nn.BatchNorm2d(channels)
        self.act   = nn.ReLU(inplace=True)
    def forward(self, x):
        r = self.act(self.bn1(self.conv1(x)))
        r = self.bn2(self.conv2(r))
        return self.act(x + r)

class GraphReasoning(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.fc_q   = nn.Linear(dim, dim)
        self.fc_k   = nn.Linear(dim, dim)
        self.fc_v   = nn.Linear(dim, dim)
        self.update = nn.Linear(dim, dim)
    def forward(self, feats):
        q = self.fc_q(feats)
        k = self.fc_k(feats)
        v = self.fc_v(feats)
        A = F.softmax(torch.bmm(q, k.transpose(1,2)) / feats.size(-1)**0.5, dim=-1)
        agg = torch.bmm(A, v)
        return self.update(agg)

class ExternalMemory(nn.Module):
    def __init__(self, mem_size=64, dim=256):
        super().__init__()
        self.register_buffer('mem', torch.randn(mem_size, dim))
        self.read_w     = nn.Linear(dim, mem_size)
        self.write_w    = nn.Linear(dim, mem_size)
        self.controller = nn.GRUCell(dim, dim)
    def forward(self, x):
        w_r      = F.softmax(self.read_w(x), dim=-1)
        w_w      = F.softmax(self.write_w(x), dim=-1)
        read_vec = w_r @ self.mem
        delta    = (w_w.unsqueeze(-1) * x.unsqueeze(1)).mean(0)
        with torch.no_grad(): self.mem += delta
        return self.controller(x, read_vec)

class DynamicFusionNet(nn.Module):
    def __init__(self, img_ch=3, prop_dim=32, hidden=256, n_heads=8, n_layers=6):
        super().__init__()
        self.stem = nn.Sequential(
            nn.Conv2d(img_ch, hidden//2, 7, stride=2, padding=3, bias=False),
            nn.BatchNorm2d(hidden//2), nn.ReLU(inplace=True),
            ResidualBlock(hidden//2), ResidualBlock(hidden//2)
        )
        self.proj_token = nn.Linear(hidden//2, hidden)
        self.prop_enc   = nn.Sequential(
            nn.Linear(prop_dim, hidden), nn.ReLU(inplace=True),
            nn.Linear(hidden, hidden),   nn.ReLU(inplace=True)
        )
        layer = nn.TransformerEncoderLayer(d_model=hidden, nhead=n_heads, dim_feedforward=hidden*4)
        self.transformer = nn.TransformerEncoder(layer, num_layers=n_layers)
        self.graph       = GraphReasoning(hidden)
        self.memory      = ExternalMemory(mem_size=32, dim=hidden)
        self.head        = nn.Sequential(
            nn.LayerNorm(hidden),
            nn.Linear(hidden, hidden//2), nn.ReLU(inplace=True),
            nn.Linear(hidden//2, hidden)
        )
    def forward(self, x_img, x_prop):
        v   = self.stem(x_img).flatten(2).transpose(1,2)
        v   = self.proj_token(v)
        p   = self.prop_enc(x_prop).unsqueeze(1)
        seq = torch.cat([v, p], dim=1)
        t   = self.transformer(seq.transpose(0,1)).transpose(0,1)
        g   = self.graph(t)
        agg = g.mean(dim=1)
        return self.head(self.memory(agg))

# â€”â€”â€”â€”â€”â€”â€” Flask App â€”â€”â€”â€”â€”â€”â€”

app = Flask(__name__)
model = DynamicFusionNet().eval()

transform = T.Compose([
    T.Resize((224,224)),
    T.ToTensor()
])

HTML = """
<!DOCTYPE html>
<html lang="ar">
<head><meta charset="UTF-8"><title>Smart Robot Brain</title></head>
<body style="font-family:sans-serif;text-align:center;margin-top:50px;">
  <h1>ðŸ¤– ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±ÙˆØ¨ÙˆØª Ø§Ù„Ø°ÙƒÙŠ</h1>
  <form method="post" enctype="multipart/form-data">
    <p><input type="file" name="image"></p>
    <p><input type="text" name="sensors" placeholder="Ù‚ÙŠÙ… Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„"></p>
    <p><button type="submit">Ø§Ø³ØªØ¹Ù„Ù… Ø§Ù„Ø¯Ù…Ø§Øº</button></p>
  </form>
  {% if output %}
    <h2>ðŸ§  Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ø¯Ù…Ø§Øº</h2>
    <pre>{{ output }}</pre>
  {% endif %}
</body>
</html>
"""

@app.route("/", methods=["GET","POST"])
def index():
    output = None
    if request.method == "POST":
        # ØµÙˆØ±Ø©
        f = request.files.get("image")
        if f:
            img = Image.open(io.BytesIO(f.read())).convert("RGB")
            x_img = transform(img).unsqueeze(0)
        else:
            x_img = torch.randn(1,3,224,224)
        # Ø­Ø³Ø§Ø³Ø§Øª
        s = request.form.get("sensors","")
        try:
            vals = [float(v) for v in s.split(",")][:32]
            x_prop = torch.tensor(vals + [0]*(32-len(vals))).unsqueeze(0)
        except:
            x_prop = torch.randn(1,32)
        # inference
        with torch.no_grad():
            out = model(x_img, x_prop)
        output = out.squeeze(0).tolist()
    return render_template_string(HTML, output=output)

if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=5000)
